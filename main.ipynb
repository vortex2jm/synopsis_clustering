{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ciência de Dados - Trabalho Prático\n",
    "\n",
    "> **Nomes:** Bruno Santos Fernandes, João Paulo Moura Clevelares, Thamya Vieira Hashimoto Donadia <br>\n",
    "> **Matrículas:** 2021100784, 2021100149, 2021100146 <br>\n",
    "> **E-mails:** {bruno.s.fernandes, joao.clevelares, thamya.donadia}@edu.ufes.br <br>\n",
    "> **Curso:** Engenharia de Computação <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodologia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instalação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importação de bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import unidecode\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pré-processamento dos dados textuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregamento do dataset \n",
    "df = pd.read_csv(\"./filmes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenção das informações gerais do dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando as features do dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtendo a feature a ser processada (sinopse)\n",
    "df['sinopse'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divisão do texto em sentenças e palavras\n",
    "df['sentences'] = df['sinopse'].apply(sent_tokenize)\n",
    "df['tokens'] = df['sinopse'].apply(word_tokenize)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversão do texto para letras minúsculas\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [token.lower() for token in x])\n",
    "df['tokens'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remoção de símbolos de pontuação de cada token\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [token.translate(table) for token in x])\n",
    "df['tokens'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversão de caracteres especiais\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [unidecode.unidecode(token) for token in x])\n",
    "df['tokens'].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remoção de tokens que não são palavras\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [token for token in x if token.isalpha()])\n",
    "df['tokens'].head(10)\n",
    "\n",
    "# TODO: Talvez seja necessário usar alguns tokens númericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remoção de stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [token for token in x if token not in stop_words])\n",
    "df['tokens'].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming \n",
    "df['tokens'] = df['tokens'].apply(lambda x: [PorterStemmer().stem(token) for token in x])\n",
    "df['tokens'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amostragem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df[[\"sinopse\", \"tokens\", \"genres\"]].sample(frac=0.2, random_state=42)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construção da matriz de TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerando a matriz de contagem de termos \n",
    "vectorizer = CountVectorizer()\n",
    "X_counts = vectorizer.fit_transform(sample[\"sinopse\"])\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculando a frequência de documentos em que cada termo aparece\n",
    "doc_freq = np.array((X_counts > 0).sum(axis=0)).flatten()\n",
    "df_vocab = pd.DataFrame({'termo': vocab, 'doc_freq': doc_freq})\n",
    "df_vocab[df_vocab['doc_freq'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# análise estatística descritiva\n",
    "mean = np.mean(doc_freq)\n",
    "median = np.median(doc_freq)\n",
    "percentiles = np.percentile(doc_freq, [25, 50, 75])\n",
    "\n",
    "print(\"Estatísticas da frequência dos termos:\")\n",
    "print(f\"Média: {mean:.2f}\")\n",
    "print(f\"Mediana: {median}\")\n",
    "print(f\"Percentis 25, 50 e 75: {percentiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotando o histrogama da frequência dos termos\n",
    "sns.displot(df_vocab, x=df_vocab['doc_freq'], kde=True, bins=50, log_scale=(True, False))\n",
    "plt.ylabel('Número de termos')\n",
    "plt.xlabel('Número de Documentos em que o termo aparece')\n",
    "plt.title('Distribuição da Frequência dos Termos no Corpus')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df_vocab['doc_freq'])\n",
    "plt.xlabel('Número de Documentos em que o termo aparece')\n",
    "plt.title('Boxplot da Frequência dos Termos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 2)\n",
    "X = vectorizer.fit_transform(sample[\"tokens\"].apply(lambda tokens: \" \".join(tokens)))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = pd.DataFrame(X.todense(), columns = vectorizer.get_feature_names_out())\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redução de dimensionalidade, via Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_full = X.shape[1]\n",
    "svd_full = TruncatedSVD(n_components=n_components_full)\n",
    "svd_full.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotando a variância cumulativa\n",
    "cumulative_variance = np.cumsum(svd_full.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(np.arange(1, min(X.shape[0], X.shape[1]) + 1), cumulative_variance)\n",
    "plt.xlabel(r'$k$ - Número de componentes principais')\n",
    "plt.ylabel(r'$f(k)$ - Fração cumulativa da variância explicada')\n",
    "plt.title('Variância Explicada Cumulativa com TruncatedSVD')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_n_components = 2500\n",
    "svd = TruncatedSVD(n_components=new_n_components)\n",
    "X2 = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando Inércia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inércial\n",
    "inertia = []\n",
    "for i in range(1, 30):\n",
    "  km = KMeans(n_clusters = i)\n",
    "  km.fit(X2)\n",
    "  inertia.append(km.inertia_)\n",
    "\n",
    "# Scatter\n",
    "plt.scatter(range(1, 30), inertia)\n",
    "_ = plt.ylabel(\"Função Objetivo\")\n",
    "_ = plt.xlabel(r\"$k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusterização\n",
    "kmeans = KMeans(n_clusters = 20)\n",
    "kmeans.fit(X2)\n",
    "y_kmeans = kmeans.predict(X2)\n",
    "\n",
    "# Vetor com os clusters de cada sinopse\n",
    "y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzindo dimensionalidade para o plot\n",
    "pca = PCA(n_components=2)\n",
    "X2_reduced = pca.fit_transform(X2)\n",
    "X2_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X2_reduced[:, 0], X2_reduced[:, 1], c=y_kmeans, cmap=plt.cm.tab20, s=50)\n",
    "plt.xlabel('Componente 1')\n",
    "plt.ylabel('Componente 2')\n",
    "plt.title('Visualização dos Clusters com KMeans')\n",
    "plt.colorbar(label='Cluster', ticks=range(20))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentual de Gêneros em cada Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando nova coluna com os clusters\n",
    "sample[\"cluster\"] = y_kmeans\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_exploded = sample[\"genres\"].str.split(',').explode(\"genres\")\n",
    "\n",
    "# Agregando tuplas por (genero + cluster) para contagem de frequencia de generos por cluster\n",
    "g_freq = sample.groupby([\"genres\", \"cluster\"]).size().reset_index(name=\"freq\")\n",
    "g_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando dados para formato matricial\n",
    "df_pivot = g_freq.pivot_table(index='genres', columns='cluster', values='freq', fill_value=0)\n",
    "df_pivot = df_pivot.astype(int)\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "plt.figure(figsize=(8, 12))\n",
    "sns.heatmap(df_pivot, cmap=\"Reds\", linewidths=1)\n",
    "plt.title('Heatmap de Frequência de Gêneros por Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Gênero')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Step -> Separar Generos agrupados nas linhas\n",
    "exploded_sample = sample\n",
    "exploded_sample[\"genres\"] = exploded_sample[\"genres\"].str.split(',')\n",
    "exploded_sample = exploded_sample.explode(\"genres\")\n",
    "exploded_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregando por (cluster + genero) para descobrir frequencia\n",
    "genre_frequency = exploded_sample.groupby([\"genres\", \"cluster\"]).size().reset_index(name=\"freq\")\n",
    "genre_frequency\n",
    "\n",
    "# Transformando amostra em formato matricial\n",
    "df_pivot = genre_frequency.pivot_table(index='genres', columns='cluster', values='freq', fill_value=0)\n",
    "df_pivot = df_pivot.astype(int)\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df_pivot, cmap=\"Reds\", linewidths=1)\n",
    "plt.title('Heatmap de Frequência de Gêneros por Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Gênero')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
